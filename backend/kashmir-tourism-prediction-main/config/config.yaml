# Kashmir Tourism Prediction Project - Configuration File

# All paths and parameters in one place for easy management

# Project metadata
project:
  name: "Kashmir Tourism Footfall Prediction"
  version: "1.0.0"
  description: "Predictive model for tourist footfall in Kashmir regions"

# Directory paths
paths:
  # Raw data (original input files)
  raw_data: "data/raw"

  # Interim data (intermediate processing)
  interim_data: "data/interim"
  weather_raw: "data/interim/weather_data"
  weather_daily: "data/interim/daily_weather_data"
  weather_monthly: "data/interim/monthly_weather_data"
  footfall_generated: "data/interim/generated_footfall"

  # Processed data (final datasets)
  processed_data: "data/processed"

  # Model-ready data (feature engineered)
  model_ready: "data/model_ready"

  models: "models"

  # Logs
  logs: "logs"

# File names
files:
  # Input files
  tourist_sites_footfall: "kashmir_tourist_sites_footfall.csv"
  monthly_tourist_data: "monthly_tourist_data_2020_2024.csv"

  # Output files
  weather_combined: "kashmir_weather_monthly_combined.csv"
  footfall_generated: "kashmir_sites_monthly_footfall_2017_2024.csv"
  final_dataset: "kashmir_tourism_dataset_final.csv"
  feature_engineered: "kashmir_tourism_simple_label.csv"

# Weather data collection settings
weather:
  api_url: "https://archive-api.open-meteo.com/v1/archive"

  # Tourist locations with coordinates
  locations:
    - name: "gulmarg"
      latitude: 34.0500
      longitude: 74.3800

    - name: "pahalgam"
      latitude: 34.0164
      longitude: 75.3181

    - name: "doodpathri"
      latitude: 33.8614
      longitude: 74.5672

    - name: "sonamarg"
      latitude: 34.3032
      longitude: 75.2922

    - name: "kokernag"
      latitude: 33.6369
      longitude: 75.1869

    - name: "aharbal"
      latitude: 33.7214
      longitude: 74.8742

    - name: "yousmarg"
      latitude: 33.8467
      longitude: 74.6869

    - name: "manasbal"
      latitude: 34.2367
      longitude: 74.6753

    - name: "lolab, bungus, keran, teetwal"
      latitude: 34.4264
      longitude: 74.4442

    - name: "gurez"
      latitude: 34.6500
      longitude: 74.8833

  # Updated parameters - remove some, add humidity and sunshine
  parameters:
    - "temperature_2m_mean"
    - "temperature_2m_max"
    - "temperature_2m_min"
    - "precipitation_sum"
    - "snowfall_sum"
    - "precipitation_hours"
    - "relative_humidity_2m_mean"  # ADDED
    - "sunshine_duration"           # ADDED
    - "windgusts_10m_max"

  # Date ranges (2019 excluded due to political unrest)
  date_ranges:
    - start: "2017-01-01"
      end: "2018-12-31"
    - start: "2020-01-01"
      end: "2024-12-31"

  # API rate limiting and retry configuration
  request_delay: 5.0              # Base delay between requests
  max_retries: 3                  # Number of retry attempts
  retry_delays: [10, 30, 60]      # Delay for each retry attempt (seconds)
  timeout: 30                     # Request timeout (seconds)

  # Columns to remove during processing
  columns_to_remove:
    - "latitude"
    - "longitude"
    - "elevation"
    - "timezone"
    - "timezone_abbreviation"

# Footfall data generation and processing
footfall:
  # Years to generate data for (historical estimation)
  generated_years:
    - 2017
    - 2018

  # Known data years (from actual datasets)
  known_years:
    - 2020
    - 2021
    - 2022
    - 2023
    - 2024

  # Excluded years (data quality issues)
  excluded_years:
    - 2019

  # Growth rate ranges for generated years
  growth_rates:
    min: 0.10
    max: 0.25

  # Normalization settings for anomalous years
  normalization:
    enabled: true
    baseline_years: [2021, 2022, 2023, 2024]
    anomalous_years: [2017, 2018, 2020]
    method: "z-score-with-floor"
    min_footfall: 1000  # Minimum visitors per month per location

  # Outlier capping configuration (NEW!)
  outlier_capping:
    enabled: true
    method: "percentile"  # Global percentile-based cap
    percentile: 99  # Cap at 99th percentile (top 1% of data)
    # This catches only extreme outliers while preserving 99% of natural data distribution

  # Monthly distribution patterns
  peak_months: [5, 6, 7, 8]
  shoulder_months: [3, 4, 9, 10]
  low_months: [1, 2, 11, 12]


# Data merging settings
merge:
  # Location name mapping (weather uses lowercase)
  location_mapping:
    "Gulmarg": "gulmarg"
    "Pahalgam": "pahalgam"
    "Doodpathri": "doodpathri"
    "Sonamarg": "sonamarg"
    "Kokernag": "kokernag"
    "Aharbal": "aharbal"
    "Yousmarg": "yousmarg"
    "Manasbal": "manasbal"
    "Lolab Bungus, Keran Teetwal": "lolab, bungus, keran, teetwal"
    "Gurez": "gurez"

# Feature engineering settings
features:
  # Rolling window for footfall average
  rolling_window: 3

  # Season mapping
  seasons:
    winter: [12, 1, 2]
    spring: [3, 4, 5]
    summer: [6, 7, 8]
    autumn: [9, 10, 11]

  # Columns to drop after feature creation
  drop_columns:
    - "time"
    - "tourist_site"

# Logging settings
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "pipeline_execution.log"

# Model training configuration
modeling:
  # Train/test split
  test_size: 0.2                # 20% for testing
  validation_size: 0.1          # 10% for validation
  random_state: 42              # For reproducibility

  # Time-series split (recommended for time-series data)
  use_time_split: true          # Use chronological split
  test_months: 12               # Last 12 months for testing

  # Target variable
  target: "Footfall"

  # Features to exclude from training
  exclude_features:
    - "Footfall"                # Target variable

  # Models to train
  models:
    linear_regression:
      enabled: true
      params: {}

    ridge:
      enabled: true
      params:
        alpha: [1.0, 10.0, 100.0]

    lasso:
      enabled: true
      params:
        alpha: [0.1, 1.0, 10.0]

    random_forest:
      enabled: true
      params:
        n_estimators: [100, 200]
        max_depth: [10, 20, null]
        min_samples_split: [2, 5]
        min_samples_leaf: [1, 2]

    xgboost:
      enabled: true
      params:
        n_estimators: [100, 200]
        max_depth: [5, 7, 10]
        learning_rate: [0.01, 0.1]
        subsample: [0.8, 1.0]

  # Evaluation metrics
  metrics:
    - "mae"          # Mean Absolute Error
    - "rmse"         # Root Mean Squared Error
    - "r2"           # RÂ² Score
    - "mape"         # Mean Absolute Percentage Error

  # Cross-validation
  cv_folds: 5

  # Feature scaling
  scale_features: true
  scaler_type: "standard"    # standard or minmax

  # Output paths
  model_dir: "models"
  results_dir: "results"

# ============================================================================
# ENHANCED FEATURE ENGINEERING WITH HOLIDAYS & LOG TRANSFORMATION
# ============================================================================
enhanced_features:
  # Holiday data configuration
  holidays:
    enabled: true
    filepath: "data/raw/kashmir_holidays_2017_2024.csv"

    # Feature aggregation
    aggregate_columns:
      - "holiday_count"           # Total holidays per month
      - "long_weekend_count"      # Long weekends per month
      - "national_holiday_count"  # National holidays per month
      - "festival_holiday_count"  # Festival holidays per month

  # Time-series lag features
  timeseries_features:
    enabled: true
    create_lags: true
    create_mom: true              # Month-over-month growth
    create_rolling_std: true      # 3-month and 6-month volatility

  # Interaction features (OPTION C: Conditional)
  interaction_features:
    enabled: true                 # Set to false to remove interactions
    precipitation_temperature: true

  # Target transformation
  target_transformation:
    enabled: true
    method: "log1p"               # np.log1p(x) = log(1 + x)
    inverse_method: "expm1"       # np.expm1(x) = e^x - 1

  # Output configuration
  output:
    save_both_versions: true      # Save 26-col AND 25-col versions
    with_interactions: "kashmir_tourism_26columns_LOG_TRANSFORMED.csv"
    without_interactions: "kashmir_tourism_25columns_LOG_TRANSFORMED.csv"
